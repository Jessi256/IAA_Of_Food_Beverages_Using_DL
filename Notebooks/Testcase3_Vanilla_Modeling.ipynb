{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/de/thumb/5/5b/Hochschule-aalen.svg/2000px-Hochschule-aalen.svg.png\" alt=\"last access: 29.09.2021\" width=\"400\" height=\"30\" style=\"float:right\"/>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/de/thumb/4/41/Groupe_SEB_logo.svg/1200px-Groupe_SEB_logo.svg.png\" alt=\"last access: 11.09.2022\" width=\"30\" height=\"30\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;color:#003A6C;background-color:#003A6C;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Master Thesis Jessica Weiler, M.Sc. Data Science and Business Analytics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image aesthetics assessment (IAA) of food and beverages using deep learning\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testcase 3: Vanilla Modeling\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four state-of-the-art vanilla models (weights=None) are initialized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, validation_curve, train_test_split, RandomizedSearchCV\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19, Xception, ResNet50, inception_v3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "# Image processing / Data Augmentation \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths\n",
    "\n",
    "#Set workdir\n",
    "wpth =os.path.abspath(os.getcwd()).replace(\"\\\\\",\"/\")\n",
    "\n",
    "#Save data save path\n",
    "save_data_dir = os.path.join(wpth, 'Saved_Data').replace(\"\\\\\",\"/\")\n",
    "checkpoint_dir=  os.path.join(save_data_dir, 'Checkpoint').replace(\"\\\\\",\"/\")\n",
    "df_model_histor_dir=  os.path.join(save_data_dir, 'df_model_history').replace(\"\\\\\",\"/\")\n",
    "\n",
    "\n",
    "#Set folderpath RIAA \n",
    "RIAA_pth = os.path.join(wpth, 'Dataset','RIAA').replace(\"\\\\\",\"/\")\n",
    "\n",
    "RIAA_train_pth = os.path.join(RIAA_pth, 'Data_Split', 'train').replace(\"\\\\\",\"/\")\n",
    "RIAA_test_pth = os.path.join(RIAA_pth, 'Data_Split', 'test').replace(\"\\\\\",\"/\")\n",
    "RIAA_val_pth = os.path.join(RIAA_pth, 'Data_Split', 'val').replace(\"\\\\\",\"/\")\n",
    "\n",
    "RIAA_224_train_pth = os.path.join(RIAA_pth, 'Data_Split_224', 'train').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_test_pth = os.path.join(RIAA_pth, 'Data_Split_224', 'test').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_val_pth = os.path.join(RIAA_pth, 'Data_Split_224', 'val').replace(\"\\\\\",\"/\")\n",
    "\n",
    "RIAA_224_binary_balanced_train_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_Balanced_224', 'train').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_binary_balanced_test_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_Balanced_224', 'test').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_binary_balanced_val_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_Balanced_224', 'val').replace(\"\\\\\",\"/\")\n",
    "\n",
    "RIAA_224_binary_warped_train_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_224', 'train').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_binary_warped_test_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_224', 'test').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_binary_warped_val_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_224', 'val').replace(\"\\\\\",\"/\")\n",
    "\n",
    "RIAA_224_binary_cropped_train_pth = os.path.join(RIAA_pth, 'Data_Split_Resized_Cropped_224', 'train').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_binary_cropped_test_pth = os.path.join(RIAA_pth, 'Data_Split_Resized_Cropped_224', 'test').replace(\"\\\\\",\"/\")\n",
    "RIAA_224_binary_cropped_val_pth = os.path.join(RIAA_pth, 'Data_Split_Resized_Cropped_224', 'val').replace(\"\\\\\",\"/\")\n",
    "\n",
    "RIAA_299_binary_warped_train_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'train').replace(\"\\\\\",\"/\")\n",
    "RIAA_299_binary_warped_test_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test').replace(\"\\\\\",\"/\")\n",
    "RIAA_299_binary_warped_val_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'val').replace(\"\\\\\",\"/\")\n",
    "\n",
    "\n",
    "#Set folderpath GPD \n",
    "GPD_pth = os.path.join(wpth, 'Dataset', 'GPD').replace(\"\\\\\",\"/\")\n",
    "\n",
    "GPD_test_pth = os.path.join(GPD_pth, 'Data').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of RIAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import splitfolders\n",
    "#splitfolders.ratio(os.path.join(RIAA_pth, 'Resized_Cropped_224').replace(\"\\\\\",\"/\"), output=os.path.join(RIAA_pth, 'Data_Split_Resized_Cropped_224'), seed=1337, ratio=(.8, 0.1,0.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip=True)\n",
    "datagen_test = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStop\n",
    "callback_earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and iterate dataset\n",
    "train_data = datagen.flow_from_directory(RIAA_224_binary_warped_train_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=True, seed=seed_value)\n",
    "val_data = datagen_test.flow_from_directory(RIAA_224_binary_warped_val_pth, class_mode='binary',target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )\n",
    "test_data = datagen_test.flow_from_directory(RIAA_224_binary_warped_test_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_obj = VGG16(include_top = False, weights=None,input_shape = (224,224,3))    #  include_top = False is used to skip the layer from flattern\n",
    "#for layer in vgg16_obj.layers:             # Off the training of the trainable parameters\n",
    "#    layer.trainable = False\n",
    "vgg16_obj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16_obj.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = vgg16_obj.get_layer('block5_pool')\n",
    "last_output = vgg16_obj.output\n",
    "\n",
    "x = Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(4096, activation='relu')(x) #, kernel_initializer=tf.keras.initializers.glorot_normal(seed=seed_value),\n",
    "                 # bias_initializer=tf.keras.initializers.Zeros()\n",
    "#x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge\n",
    "model = tf.keras.Model(vgg16_obj.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9,\n",
    "    nesterov=True),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model_dir=  os.path.join(checkpoint_dir, 'vanilla_vgg16_base_model-{epoch:03d}-{accuracy:.3f}-{val_accuracy:.3f}.h5').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_model_dir,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_classifier = model.fit(train_data, validation_data=val_data, verbose=1,  callbacks=[callback_earlystop, checkpoint_callback], epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = time.time()\n",
    "time_delta=stop_time - start_time\n",
    "print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "str(datetime.timedelta(seconds=time_delta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model history\n",
    "df_history =pd.DataFrame(vgg_classifier.history)\n",
    "model_history_dir=  os.path.join(df_model_histor_dir, 'df_history_vanilla_vgg16_base_model.csv').replace(\"\\\\\",\"/\")\n",
    "df_history.to_csv(model_history_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg_classifier.history['accuracy'])\n",
    "plt.plot(vgg_classifier.history['val_accuracy'])\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vgg_classifier.history['loss'])\n",
    "plt.plot(vgg_classifier.history['val_loss'])\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)\n",
    "pd.DataFrame(classification_report(test_data.classes, pred > 0.5, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reality = [0 if x > 0.5 else 1 for x in true_classes]\n",
    "#reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0 if x > 0.5 else 1 for x in pred]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(reality, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = pred.round() \n",
    "class_labels = list(test_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot= True, xticklabels = ['Pred: 0_Unaesthetic', 'Pred: 1_Aesthetic'],\n",
    "           yticklabels = ['True: 0_Unaesthetic', 'True: 1_Aesthetic'], cmap='Blues', fmt='g').set_title('Evaluation VGG16 base model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "image_size=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and iterate dataset\n",
    "train_data = datagen.flow_from_directory(RIAA_224_binary_warped_train_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=True, seed=seed_value)\n",
    "val_data = datagen_test.flow_from_directory(RIAA_224_binary_warped_val_pth, class_mode='binary',target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )\n",
    "test_data = datagen_test.flow_from_directory(RIAA_224_binary_warped_test_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_obj = ResNet50(include_top = False, weights=None,input_shape = (224,224,3))    #  include_top = False is used to skip the layer from flattern\n",
    "#for layer in resnet50_obj.layers:             # Off the training of the trainable parameters\n",
    "#    layer.trainable = False\n",
    "resnet50_obj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_obj.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = resnet50_obj.get_layer('conv5_block3_out')\n",
    "last_output = resnet50_obj.output\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(last_output)\n",
    "#x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge\n",
    "model = tf.keras.Model(resnet50_obj.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model_dir=  os.path.join(checkpoint_dir, 'vanilla_Resnet50_base_model-{epoch:03d}-{accuracy:.3f}-{val_accuracy:.3f}.h5').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_model_dir,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStop\n",
    "callback_earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9,\n",
    "    nesterov=True),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_classifier = model.fit(train_data, validation_data=val_data, verbose=1,  callbacks=[callback_earlystop, checkpoint_callback ], epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = time.time()\n",
    "time_delta=stop_time - start_time\n",
    "print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "str(datetime.timedelta(seconds=time_delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model history\n",
    "df_history =pd.DataFrame(resnet50_classifier.history)\n",
    "model_history_dir=  os.path.join(df_model_histor_dir, 'df_history_vanilla_resnet50_base_model.csv').replace(\"\\\\\",\"/\")\n",
    "df_history.to_csv(model_history_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resnet50_classifier.history['val_accuracy'])\n",
    "plt.plot(resnet50_classifier.history['accuracy'])\n",
    "plt.legend(['val','train'], loc='upper left')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resnet50_classifier.history['val_loss'])\n",
    "plt.plot(resnet50_classifier.history['loss'])\n",
    "plt.legend(['val','train'], loc='upper left')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)\n",
    "pd.DataFrame(classification_report(test_data.classes, pred > 0.5, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reality = [0 if x > 0.5 else 1 for x in true_classes]\n",
    "#reality\n",
    "predictions = [0 if x > 0.5 else 1 for x in pred]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(reality, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = pred.round() #round_pred#np.argmax(round_pred, axis=1)\n",
    "#true_classes = test_data.classes\n",
    "class_labels = list(test_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot= True, xticklabels = ['Pred: 0_Unaesthetic', 'Pred: 1_Aesthetic'],\n",
    "           yticklabels = ['True: 0_Unaesthetic', 'True: 1_Aesthetic'], cmap='Blues', fmt='g').set_title('Evaluation ResNet50 base model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and iterate dataset\n",
    "train_data = datagen.flow_from_directory(RIAA_299_binary_warped_train_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=True, seed=seed_value)\n",
    "val_data = datagen_test.flow_from_directory(RIAA_299_binary_warped_val_pth, class_mode='binary',target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )\n",
    "test_data = datagen_test.flow_from_directory(RIAA_299_binary_warped_test_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3_obj = InceptionV3(include_top = False, input_shape = (299,299,3), weights=None)    #  include_top = False is used to skip the layer from flattern\n",
    "inceptionv3_obj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionv3_obj.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = inceptionv3_obj.get_layer('mixed10')\n",
    "last_output = inceptionv3_obj.output\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(last_output)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge\n",
    "model = tf.keras.Model(inceptionv3_obj.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model_dir=  os.path.join(checkpoint_dir, 'vanilla_InceptionV3_base_model-{epoch:03d}-{accuracy:.3f}-{val_accuracy:.3f}.h5').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_model_dir,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStop\n",
    "callback_earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9,\n",
    "    nesterov=True),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inceptionv3_classifier = model.fit(train_data, validation_data=val_data, verbose=1,  callbacks=[callback_earlystop, checkpoint_callback ], epochs=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = time.time()\n",
    "time_delta=stop_time - start_time\n",
    "print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "str(datetime.timedelta(seconds=time_delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model history\n",
    "df_history =pd.DataFrame(inceptionv3_classifier.history)\n",
    "model_history_dir=  os.path.join(df_model_histor_dir, 'vanilla_inceptionv3_classifier_base_model.csv').replace(\"\\\\\",\"/\")\n",
    "df_history.to_csv(model_history_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inceptionv3_classifier.history['val_accuracy'])\n",
    "plt.plot(inceptionv3_classifier.history['accuracy'])\n",
    "plt.legend(['val','train'], loc='upper left')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inceptionv3_classifier.history['val_loss'])\n",
    "plt.plot(inceptionv3_classifier.history['loss'])\n",
    "plt.legend(['val','train'], loc='upper left')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)\n",
    "pd.DataFrame(classification_report(test_data.classes, pred > 0.5, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reality = [0 if x > 0.5 else 1 for x in true_classes]\n",
    "#reality\n",
    "predictions = [0 if x > 0.5 else 1 for x in pred]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(reality, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = pred.round()\n",
    "class_labels = list(test_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot= True, xticklabels = ['Pred: 0_Unaesthetic', 'Pred: 1_Aesthetic'],\n",
    "            \n",
    "           yticklabels = ['True: 0_Unaesthetic', 'True: 1_Aesthetic'], cmap='Blues', fmt='g').set_title('Evaluation Inceptionv3 base model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and iterate dataset\n",
    "train_data = datagen.flow_from_directory(RIAA_299_binary_warped_train_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=True, seed=seed_value)\n",
    "val_data = datagen_test.flow_from_directory(RIAA_299_binary_warped_val_pth, class_mode='binary',target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )\n",
    "test_data = datagen_test.flow_from_directory(RIAA_299_binary_warped_test_pth, class_mode='binary', target_size=(image_size, image_size),batch_size=32, shuffle=False, seed=seed_value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_obj = Xception(include_top = False, input_shape = (299,299,3), weights=None)    #  include_top = False is used to skip the layer from flattern\n",
    "Xception_obj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_obj.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = Xception_obj.get_layer('block14_sepconv2_act')\n",
    "last_output = Xception_obj.output\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(last_output)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge\n",
    "model = tf.keras.Model(Xception_obj.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model_dir=  os.path.join(checkpoint_dir, 'vanilla_Xception_base_model-{epoch:03d}-{accuracy:.3f}-{val_accuracy:.3f}.h5').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_model_dir,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStop\n",
    "callback_earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9,\n",
    "    nesterov=True),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_classifier = model.fit(train_data, validation_data=val_data, verbose=1,  callbacks=[callback_earlystop, checkpoint_callback ], epochs=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = time.time()\n",
    "time_delta=stop_time - start_time\n",
    "print(\"--- %s seconds ---\" % (stop_time - start_time))\n",
    "str(datetime.timedelta(seconds=time_delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model history\n",
    "df_history =pd.DataFrame(xception_classifier.history)\n",
    "model_history_dir=  os.path.join(df_model_histor_dir, 'xception_classifier_base_model.csv').replace(\"\\\\\",\"/\")\n",
    "df_history.to_csv(model_history_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xception_classifier.history['val_accuracy'])\n",
    "plt.plot(xception_classifier.history['accuracy'])\n",
    "plt.legend(['val','train'], loc='upper left')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xception_classifier.history['val_loss'])\n",
    "plt.plot(xception_classifier.history['loss'])\n",
    "plt.legend(['val','train'], loc='upper left')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)\n",
    "pd.DataFrame(classification_report(test_data.classes, pred > 0.5, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reality = [0 if x > 0.5 else 1 for x in true_classes]\n",
    "#reality\n",
    "predictions = [0 if x > 0.5 else 1 for x in pred]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(reality, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = pred.round()\n",
    "class_labels = list(test_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot= True, xticklabels = ['Pred: 0_Unaesthetic', 'Pred: 1_Aesthetic'],\n",
    "            \n",
    "           yticklabels = ['True: 0_Unaesthetic', 'True: 1_Aesthetic'], cmap='Blues', fmt='g').set_title('Evaluation Xception base model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_inceptionv3.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_pred_list= []\n",
    "wrong_pred_list= []\n",
    "classes=list(test_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1809):\n",
    "    if int(pred[i].round())==test_data.classes[i]:\n",
    "        right_pred_list.append(i)   \n",
    "    else:\n",
    "        wrong_pred_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(right_pred_list)\n",
    "random.shuffle(wrong_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(12):\n",
    "    element= right_pred_list[i]\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    img_url=test_data.filenames[element]\n",
    "    full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    title_text= classes[int(pred[element].round())]\n",
    "    #f'Pred: {int(pred[element].round())}, True: {test_data.classes[element]}'\n",
    "    \n",
    "    if int(pred[element].round())==test_data.classes[element]:\n",
    "        color='g'\n",
    "    else:\n",
    "        color='r'\n",
    "    \n",
    "    img = plt.imread(full_img_pth)\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.title(title_text, color=color) \n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(12):\n",
    "    element= wrong_pred_list[i]\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    img_url=test_data.filenames[element]\n",
    "    full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    title_text=f' Prediction: {classes[int(pred[element].round())]}'\n",
    "    #f'Pred: {int(pred[element].round())}, True: {test_data.classes[element]}'\n",
    "    \n",
    "    if int(pred[element].round())==test_data.classes[element]:\n",
    "        color='g'\n",
    "    else:\n",
    "        color='r'\n",
    "    \n",
    "    img = plt.imread(full_img_pth)\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.title(title_text, color=color) \n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=7\n",
    "specific_img_element=wrong_pred_list[number]\n",
    "img_url=test_data.filenames[specific_img_element]\n",
    "full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(full_img_pth)\n",
    "plt.imshow(img, cmap='jet') \n",
    "pred_value_round=[ '%.4f' % elem for elem in pred[specific_img_element]]\n",
    "title_text= f'Prediction:  {100-(float(pred_value_round[0])* 100)} % for {classes[int(pred[element].round())]} \\n True class:  {classes[test_data.classes[element]]}                         .'\n",
    "#f'Prediction: {pred_value_round[0]}≈{int(pred[specific_img_element].round())}, True Class: {test_data.classes[specific_img_element]}'\n",
    "plt.title(title_text, color='black')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=5\n",
    "specific_img_element=wrong_pred_list[number]\n",
    "img_url=test_data.filenames[specific_img_element]\n",
    "full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread(full_img_pth)\n",
    "plt.imshow(img, cmap='jet') \n",
    "pred_value_round=[ '%.4f' % elem for elem in pred[specific_img_element]]\n",
    "title_text= f'Prediction:  {100-(float(pred_value_round[0])* 100)} % for {classes[int(pred[element].round())]} \\n True class:  {classes[test_data.classes[element]]}                        .'\n",
    "#f'Prediction: {pred_value_round[0]}≈{int(pred[specific_img_element].round())}, True Class: {test_data.classes[specific_img_element]}'\n",
    "plt.title(title_text, color='black')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=11\n",
    "specific_img_element=wrong_pred_list[number]\n",
    "img_url=test_data.filenames[specific_img_element]\n",
    "full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread(full_img_pth)\n",
    "plt.imshow(img, cmap='jet') \n",
    "pred_value_round=[ '%.4f' % elem for elem in pred[specific_img_element]]\n",
    "title_text= f'Prediction:  {100 - (float(pred_value_round[0]) *100)} % for {classes[int(pred[element].round())]} \\n    True class:  {classes[test_data.classes[element]]}                          .'\n",
    "#f'Prediction: {pred_value_round[0]}≈{int(pred[specific_img_element].round())}, True Class: {test_data.classes[specific_img_element]}'\n",
    "plt.title(title_text, color='black')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on boarderline images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RIAA_299_warped_boarderline_pth= os.path.join(r'.\\RIAA\\Data_Split_299\\train\\2_NotSure').replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "#https://stackoverflow.com/questions/43469281/how-to-predict-input-image-using-trained-model-in-keras 05.12.2022\n",
    "\n",
    "def load_image(img_path, size):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(size,size))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    return img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "path= os.path.join(RIAA_299_warped_boarderline_pth, '*').replace(\"\\\\\",\"/\")\n",
    "some_boarderline_images = glob(path, recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "#pred_value_round=[ '%.4f' % elem for elem in pred[0]]\n",
    "\n",
    "for i in range(12):\n",
    "    \n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    img_url=some_boarderline_images[i]\n",
    "    #full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_299', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    img_tensor= load_image(img_url,299)\n",
    "    pred = model.predict(img_tensor)\n",
    "    pred_value_round=[ '%.4f' % elem for elem in pred[0]]\n",
    "    title_text= f'Pred: {pred_value_round[0]}≈{int(pred[0].round())} '    \n",
    "    img = plt.imread(img_url)\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.title(title_text) \n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best models\n",
    "model_vgg16 = tf.keras.models.load_model(os.path.join(checkpoint_dir, 'vanilla_vgg16_base_model-027-0.788-0.807.h5').replace(\"\\\\\",\"/\"))\n",
    "model_resnet50 = tf.keras.models.load_model(os.path.join(checkpoint_dir, 'vanilla_Resnet50_base_model-013-0.790-0.791.h5').replace(\"\\\\\",\"/\"))\n",
    "model_inceptionv3 = tf.keras.models.load_model(os.path.join(checkpoint_dir, 'vanilla_InceptionV3_base_model-020-0.810-0.807.h5').replace(\"\\\\\",\"/\"))\n",
    "model_xception = tf.keras.models.load_model(os.path.join(checkpoint_dir, 'vanilla_Xception_base_model-006-0.797-0.804.h5').replace(\"\\\\\",\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\"vgg16\",  \"resnet50\", \"inceptionv3\", \"xception\"]\n",
    "image_size = [224, 224, 299, 299]\n",
    "seed_value=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,i in enumerate(test_cases):\n",
    "    print('---------- %s ----------' % i)\n",
    "    \n",
    "    # load and iterate dataset\n",
    "    train_data = datagen.flow_from_directory(globals()[\"RIAA_\" + str(image_size[j]) + \"_binary_warped_train_pth\"], class_mode='binary', target_size=(image_size[j], image_size[j]),batch_size=32, shuffle=True, seed=seed_value)\n",
    "    val_data = datagen_test.flow_from_directory(globals()[\"RIAA_\" + str(image_size[j]) + \"_binary_warped_val_pth\"], class_mode='binary',target_size=(image_size[j], image_size[j]),batch_size=32, shuffle=False, seed=seed_value)\n",
    "    test_data = datagen_test.flow_from_directory(globals()[\"RIAA_\" + str(image_size[j])+ \"_binary_warped_test_pth\"], class_mode='binary', target_size=(image_size[j], image_size[j]),batch_size=32, shuffle=False, seed=seed_value )\n",
    "    generalization_test = datagen_test.flow_from_directory(GPD_test_pth, class_mode='binary', target_size=(image_size[j], image_size[j]),batch_size=32, shuffle=False, seed=seed_value )\n",
    "    \n",
    "    globals()[\"Eval_train_\"+\"model_\"+str(i)] = globals()[\"model_\"+str(i)].evaluate(train_data)\n",
    "    globals()[\"Eval_val_\"+\"model_\"+str(i)] = globals()[\"model_\"+str(i)].evaluate(val_data)\n",
    "    globals()[\"Eval_test_\"+\"model_\"+str(i)] =globals()[\"model_\"+str(i)].evaluate(test_data)\n",
    "    globals()[\"Eval_gentest_\"+\"model_\"+str(i)] =globals()[\"model_\"+str(i)].evaluate(generalization_test)\n",
    "    print('---------------------------------------------------------------' )\n",
    "    \n",
    "    print('Train accuracy')\n",
    "    print(format(globals()[\"Eval_train_\"+\"model_\"+str(i)][1], '.4f'))\n",
    "    print('----------')\n",
    "    \n",
    "    print('Validation accuracy')\n",
    "    print(format(globals()[\"Eval_val_\"+\"model_\"+str(i)][1], '.4f'))\n",
    "    print('Test accuracy')\n",
    "    print(format(globals()[\"Eval_test_\"+\"model_\"+str(i)][1], '.4f'))\n",
    "    print('Test accuracy on GPD dataset')\n",
    "    print(format(globals()[\"Eval_gentest_\"+\"model_\"+str(i)][1], '.4f'))\n",
    "    print('----------')\n",
    "    \n",
    "    globals()[\"true_classes_\"+\"model_\"+str(i)] = test_data.classes\n",
    "    #globals()[\"reality\"+\"vgg16_model_\"+str(i)] = [0 if x > 0.5 else 1 for x in globals()[\"true_classes_\"+\"vgg16_model_\"+str(i)]]\n",
    "    globals()[\"pred\"+\"model_\"+str(i)] =  globals()[\"model_\"+str(i)].predict(test_data)\n",
    "    globals()[\"pred\"+\"model_GPD\"+str(i)] =  globals()[\"model_\"+str(i)].predict(generalization_test)\n",
    "    #globals()[\"predictions\"+\"vgg16_model_\"+str(i)] = [0 if x > 0.5 else 1 for x in globals()[\"pred\"+\"vgg16_model_\"+str(i)]]\n",
    "    globals()[\"predicted_classes\"+\"model_\"+str(i)] = globals()[\"pred\"+\"model_\"+str(i)].round()\n",
    "    globals()[\"cm\"+\"model_\"+str(i)] = confusion_matrix(globals()[\"true_classes_\"+\"model_\"+str(i)], globals()[\"predicted_classes\"+\"model_\"+str(i)])\n",
    "    \n",
    "    print('TrueNegative accuracy')\n",
    "    TrueNegative=globals()[\"cm\"+\"model_\"+str(i)][0][0]/(globals()[\"cm\"+\"model_\"+str(i)][0][1]+globals()[\"cm\"+\"model_\"+str(i)][0][0])\n",
    "    print(format(TrueNegative, '.4f'))\n",
    "    print('TruePositive accuracy')\n",
    "    TruePositive=globals()[\"cm\"+\"model_\"+str(i)][1][1]/(globals()[\"cm\"+\"model_\"+str(i)][1][0]+globals()[\"cm\"+\"model_\"+str(i)][1][1])\n",
    "    print(format(TruePositive, '.4f'))\n",
    "    print('Balanced accuracy')\n",
    "    print(format((0.5*TrueNegative)+(0.5*TruePositive), '.4f'))\n",
    "    \n",
    "    sns.heatmap(globals()[\"cm\"+\"model_\"+str(i)], annot= True, xticklabels = ['Pred: 0_Unaesthetic', 'Pred: 1_Aesthetic'],\n",
    "           yticklabels = ['True: 0_Unaesthetic', 'True: 1_Aesthetic'], cmap='Blues', fmt='g').set_title('Evaluation ' + str(i) + ' model')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(12):\n",
    "    element= wrong_pred_list[i]\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    img_url=test_data.filenames[element]\n",
    "    full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    title_text=f' Prediction: {classes[int(pred[element].round())]}'\n",
    "    #f'Pred: {int(pred[element].round())}, True: {test_data.classes[element]}'\n",
    "    \n",
    "    if int(pred[element].round())==test_data.classes[element]:\n",
    "        color='g'\n",
    "    else:\n",
    "        color='r'\n",
    "    \n",
    "    img = plt.imread(full_img_pth)\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.title(title_text, color=color) \n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (50):\n",
    "    img_url=test_data.filenames[j]\n",
    "    full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    print(full_img_pth)\n",
    "    img = plt.imread(full_img_pth)\n",
    "    title_text= f'{classes[test_data.classes[j]]}'\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    print(title_text)\n",
    "    #plt.title(title_text) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    for i in test_cases:\n",
    "        print(\"pred\"+\"model_\"+str(i))\n",
    "        print(globals()[\"pred\"+\"model_\"+str(i)][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix=np.column_stack((predmodel_vgg16, predmodel_resnet50, predmodel_inceptionv3, predmodel_xception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0_1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_matrix)):\n",
    "    #for j in (test_matrix[0]):\n",
    "    if test_matrix[i][1] > 0.5 and  test_matrix[i][2] > 0.5 and  test_matrix[i][3] > 0.5 and  test_matrix[i][0] > 0.5:\n",
    "        list_0_1.append(1)\n",
    "    elif test_matrix[i][1] <= 0.5 and  test_matrix[i][2] <= 0.5 and  test_matrix[i][3] <= 0.5 and  test_matrix[i][0] <= 0.5:\n",
    "        list_0_1.append(0)\n",
    "    else:\n",
    "         list_0_1.append('N/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_true=[]\n",
    "test_list_false=[]\n",
    "classes=list(test_data.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_matrix)):\n",
    "    if list_0_1[i] == test_data.classes[i]:\n",
    "        test_list_true.append(i)\n",
    "    elif list_0_1[i] != 'N/A':\n",
    "        test_list_false.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(test_list_true)\n",
    "random.shuffle(test_list_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(12):\n",
    "    element= test_list_true[i]\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    img_url=test_data.filenames[element]\n",
    "    full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    title_text= classes[int(predmodel_vgg16[element].round())]\n",
    "\n",
    "    \n",
    "    if int(pred[element].round())==test_data.classes[element]:\n",
    "        color='g'\n",
    "    else:\n",
    "        color='r'\n",
    "    \n",
    "    img = plt.imread(full_img_pth)\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.title(title_text, color=color) \n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(12):\n",
    "    element= test_list_false[i]\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    img_url=test_data.filenames[element]\n",
    "    full_img_pth = os.path.join(RIAA_pth, 'Data_Split_Binary_300', 'test', img_url).replace(\"\\\\\",\"/\")\n",
    "    title_text= f'Prediction: {classes[int(predmodel_resnet50[element].round())]}'\n",
    "    #f'Pred: {int(pred[element].round())}, True: {test_data.classes[element]}'\n",
    "    \n",
    "    if int(predmodel_resnet50[element].round())==test_data.classes[element]:\n",
    "        color='g'\n",
    "    else:\n",
    "        color='r'\n",
    "    \n",
    "    img = plt.imread(full_img_pth)\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    plt.title(title_text, color=color) \n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization Test on GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (50):\n",
    "    img_url=generalization_test.filenames[-j]\n",
    "    full_img_pth = os.path.join(GPD_test_pth, img_url).replace(\"\\\\\",\"/\")\n",
    "    print(full_img_pth)\n",
    "    img = plt.imread(full_img_pth)\n",
    "    title_text= f'{classes[generalization_test.classes[-j]]}'\n",
    "    plt.imshow(img, cmap='jet')\n",
    "    print(title_text)\n",
    "    #plt.title(title_text) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    for i in test_cases:\n",
    "        print(\"pred\"+\"model_GPD\"+str(i))\n",
    "        print(globals()[\"pred\"+\"model_GPD\"+str(i)][-j])"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1655196706797,
  "creator": "mgros",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "modifiedBy": "jweiler",
  "tags": [],
  "versionNumber": 2
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
